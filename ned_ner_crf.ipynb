{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-family:Courier New; color:#CCCCCC\">**Dutch Named Entity Recognition CRF**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Load Data and Imports**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\Jordi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import convert_BIO\n",
    "from NER_evaluation import *\n",
    "from feature_getter import Feature_getter\n",
    "import pycrfsuite\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('conll2002')\n",
    "from nltk.corpus import conll2002\n",
    "\n",
    "ned_train = conll2002.iob_sents('ned.train')\n",
    "ned_val = conll2002.iob_sents('ned.testa')\n",
    "ned_test = conll2002.iob_sents('ned.testb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Preprocessing Data**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_train_BIO = convert_BIO(ned_train)\n",
    "ned_val_BIO = convert_BIO(ned_val)\n",
    "ned_test_BIO = convert_BIO(ned_test)\n",
    "\n",
    "X_val_BIO = [[word[0] for word in sent] for sent in ned_val_BIO]\n",
    "y_val_BIO = [[word[1] for word in sent] for sent in ned_val_BIO]\n",
    "X_test_BIO = [[word[0] for word in sent] for sent in ned_test_BIO]\n",
    "y_test_BIO = [[word[1] for word in sent] for sent in ned_test_BIO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"font-family:Courier New; color:#336666\">**Train Classifier**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary avaluation table\n",
    "results_df = pd.DataFrame()\n",
    "def save_ent_results(nclf, results, results_agg_ent, df):\n",
    "    df.loc[nclf,'total acc'] = results[\"precision\"]\n",
    "    df.loc[nclf,'total recall'] = results[\"recall\"]\n",
    "    df.loc[nclf,'total F1'] = results[\"F1-score\"]\n",
    "    df.loc[nclf,'PER F1'] = results_agg_ent[\"PER\"][\"F1-score\"]\n",
    "    df.loc[nclf,'ORG F1'] = results_agg_ent[\"ORG\"][\"F1-score\"]\n",
    "    df.loc[nclf,'LOC F1'] = results_agg_ent[\"LOC\"][\"F1-score\"]\n",
    "    df.loc[nclf,'MISC F1'] = results_agg_ent[\"MISC\"][\"F1-score\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Courier New; color:#336633\">**Default Feature Getter**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Courier New\">Feature&Hyperparameter_selection notebook suggests that best hyperparamaters for CRF.Tagger default feature getter are: {'c1': 0.01, 'c2': 0.1, 'max_iterations': 200, 'possible_transitions': True, 'possible_states': True, 'min_freq' = 0}. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_hyperparams = {'c1': 0.01, 'c2': 0.1, 'max_iterations': 200, 'feature.possible_transitions': True,\n",
    "                                            'feature.possible_states': True, 'feature.minfreq': 0}\n",
    "model = nltk.tag.CRFTagger(training_opt = default_hyperparams)\n",
    "model.train(ned_train_BIO, 'models/ned_default_BIO.tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Evalutation**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.72      0.62      0.66       479\n",
      "       I-LOC       0.53      0.30      0.38        64\n",
      "      B-MISC       0.70      0.69      0.69       748\n",
      "      I-MISC       0.26      0.42      0.32       215\n",
      "       B-ORG       0.90      0.57      0.70       686\n",
      "       I-ORG       0.79      0.65      0.71       396\n",
      "       B-PER       0.61      0.74      0.67       703\n",
      "       I-PER       0.74      0.93      0.82       423\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      3714\n",
      "   macro avg       0.66      0.61      0.62      3714\n",
      "weighted avg       0.71      0.67      0.68      3714\n",
      " samples avg       0.07      0.07      0.07      3714\n",
      "\n",
      "================================================================================\n",
      "Entity level evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total acc</th>\n",
       "      <th>total recall</th>\n",
       "      <th>total F1</th>\n",
       "      <th>PER F1</th>\n",
       "      <th>ORG F1</th>\n",
       "      <th>LOC F1</th>\n",
       "      <th>MISC F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default_BIO</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total acc  total recall  total F1  PER F1  ORG F1  LOC F1  \\\n",
       "Default_BIO      0.672         0.627     0.649   0.586   0.794   0.687   \n",
       "\n",
       "             MISC F1  \n",
       "Default_BIO     0.61  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ned_BIO = model.tag_sents(X_val_BIO)\n",
    "y_pred_BIO = [[word[1] for word in sent] for sent in pred_ned_BIO]\n",
    "\n",
    "print(bio_classification_report(y_val_BIO, y_pred_BIO))\n",
    "print('='*80)\n",
    "print('Entity level evaluation')\n",
    "print('='*80)\n",
    "results, results_agg_ent = compute_metrics(ned_val_BIO, pred_ned_BIO)\n",
    "results_df = save_ent_results(\"Default_BIO\", results, results_agg_ent, results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Feature Importance**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:                       |     Top negative:\n",
      "-----------------------------------------------------------------------------\n",
      "10.313 O      PUNCTUATION               -3.545 O      WORD_3D-Design            \n",
      "8.892 O      WORD_U                     -3.570 O      WORD_doorsnee-Hollander   \n",
      "8.098 O      SUF_E                      -3.595 O      WORD_leclicgagnant        \n",
      "7.872 O      WORD_I                     -3.612 O      WORD_oud-EU-commissievoorzitter\n",
      "7.759 O      SUF_e                      -3.634 O      WORD_toverbonen           \n",
      "7.557 O      SUF_t                      -3.678 O      WORD_racismebestrijding   \n",
      "7.399 O      SUF_f                      -4.045 O      WORD_kabinet-Aelvoet      \n",
      "7.301 O      SUF_p                      -4.211 O      WORD_pet                  \n",
      "7.267 O      SUF_m                      -4.246 O      WORD_groenen              \n",
      "7.224 O      SUF_d                      -7.079 O      CAPITALIZATION            \n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "        for (attr, label), weight in state_features:\n",
    "            string = \"%0.3f %-6s %s\" % (weight, label, attr)\n",
    "            print(string, end = \" \"*(40 - len(string)))\n",
    "\n",
    "def feature_importance(model):\n",
    "\n",
    "    info = model._tagger.info()\n",
    "    positive_features = Counter(info.state_features).most_common(10)\n",
    "    negative_features = Counter(info.state_features).most_common()[-10:]\n",
    "\n",
    "    print(\"Top positive:                       |     Top negative:\")\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "\n",
    "    for positive, negative in zip(positive_features, negative_features):\n",
    "        print_state_features([positive])\n",
    "        print_state_features([negative])\n",
    "        print()\n",
    "feature_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Courier New; color:#336633\">**Customed Feature Getter**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Courier New\">Feature&Hyperparameter_selection notebook suggests that best hyperparamaters for CRF.Tagger with customed feature getter are: {'c1': 0.01, 'c2': 1, 'max_iterations': 100, 'possible_transitions': False, 'possible_states': True, 'min_freq' = 0}. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "customed_hyperparams = {'c1': 0.01, 'c2': 1, 'max_iterations': 100, 'feature.possible_transitions': False,\n",
    "                                            'feature.possible_states': True, 'feature.minfreq': 0}\n",
    "model = nltk.tag.CRFTagger(feature_func=Feature_getter(language='ned'), training_opt = customed_hyperparams)\n",
    "model.train(ned_train_BIO, 'models/ned_customed_BIO.tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Evalutation**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.78      0.78      0.78       479\n",
      "       I-LOC       0.68      0.41      0.51        64\n",
      "      B-MISC       0.83      0.76      0.80       748\n",
      "      I-MISC       0.61      0.56      0.58       215\n",
      "       B-ORG       0.87      0.64      0.74       686\n",
      "       I-ORG       0.88      0.64      0.74       396\n",
      "       B-PER       0.72      0.87      0.79       703\n",
      "       I-PER       0.81      0.94      0.87       423\n",
      "\n",
      "   micro avg       0.79      0.75      0.77      3714\n",
      "   macro avg       0.77      0.70      0.73      3714\n",
      "weighted avg       0.80      0.75      0.77      3714\n",
      " samples avg       0.07      0.07      0.07      3714\n",
      "\n",
      "================================================================================\n",
      "Entity level evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total acc</th>\n",
       "      <th>total recall</th>\n",
       "      <th>total F1</th>\n",
       "      <th>PER F1</th>\n",
       "      <th>ORG F1</th>\n",
       "      <th>LOC F1</th>\n",
       "      <th>MISC F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default_BIO</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIO</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total acc  total recall  total F1  PER F1  ORG F1  LOC F1  \\\n",
       "Default_BIO      0.672         0.627     0.649   0.586   0.794   0.687   \n",
       "Custom_BIO       0.778         0.750     0.764   0.714   0.806   0.774   \n",
       "\n",
       "             MISC F1  \n",
       "Default_BIO    0.610  \n",
       "Custom_BIO     0.784  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ned_BIO = model.tag_sents(X_val_BIO)\n",
    "y_pred_BIO = [[word[1] for word in sent] for sent in pred_ned_BIO]\n",
    "\n",
    "print(bio_classification_report(y_val_BIO, y_pred_BIO))\n",
    "print('='*80)\n",
    "print('Entity level evaluation')\n",
    "print('='*80)\n",
    "results, results_agg_ent = compute_metrics(ned_val_BIO, pred_ned_BIO)\n",
    "results_df = save_ent_results(\"Custom_BIO\", results, results_agg_ent, results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**Feature Importance**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:                       |     Top negative:\n",
      "-----------------------------------------------------------------------------\n",
      "4.465 O      SHAPE_xxxx                 -1.071 B-MISC LEN_3                     \n",
      "3.431 O      LEN_1                      -1.109 B-PER  HAS_NUM                   \n",
      "2.941 O      PUNCTUATION                -1.131 B-ORG  SHAPE_xxx                 \n",
      "2.845 O      POS_ADV                    -1.134 B-MISC LEN_2                     \n",
      "2.807 O      POS_PUNCT                  -1.156 B-PER  -1_POS_DET                \n",
      "2.500 O      SHAPE_xxx                  -1.169 B-ORG  SHAPE_Xxx                 \n",
      "2.489 O      POS_PRON                   -1.397 B-LOC  SHAPE_xxxx                \n",
      "2.470 O      HAS_NUM                    -1.398 B-ORG  SHAPE_xxxx                \n",
      "2.405 O      LEN_2                      -1.558 B-MISC SHAPE_xxxx                \n",
      "2.107 O      SHAPE_xxxx-xxxx            -1.873 I-MISC -1_SUF_se                 \n"
     ]
    }
   ],
   "source": [
    "feature_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>See:</b> in contrast with models trained in feature&hyperparameter_selection notebook, now customed feature getter results in a much better model than default's. Thus, we will continue improving this last model, since we are not satisfied enough with results. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Courier New; color:#336633\">**Changing tagger format**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Courier New\">At this point, lets check whether changing the codification of entities has a postive impact on performance. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**IO**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_train_IO = convert_BIO(ned_train, begin = False)\n",
    "ned_val_IO = convert_BIO(ned_val, begin = False)\n",
    "ned_test_IO = convert_BIO(ned_test, begin = False)\n",
    "\n",
    "X_val_IO = [[word[0] for word in sent] for sent in ned_val_IO]\n",
    "y_val_IO = [[word[1] for word in sent] for sent in ned_val_IO]\n",
    "X_test_IO = [[word[0] for word in sent] for sent in ned_test_IO]\n",
    "y_test_IO = [[word[1] for word in sent] for sent in ned_test_IO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "customed_hyperparams = {'c1': 0.01, 'c2': 1, 'max_iterations': 100, 'feature.possible_transitions': False,\n",
    "                                            'feature.possible_states': True, 'feature.minfreq': 0}\n",
    "model = nltk.tag.CRFTagger(feature_func=Feature_getter(language='ned'), training_opt = customed_hyperparams)\n",
    "model.train(ned_train_IO, 'models/ned_customed_IO.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.77      0.75      0.76       543\n",
      "      I-MISC       0.79      0.72      0.75       963\n",
      "       I-ORG       0.88      0.66      0.75      1082\n",
      "       I-PER       0.76      0.90      0.83      1126\n",
      "\n",
      "   micro avg       0.80      0.76      0.78      3714\n",
      "   macro avg       0.80      0.76      0.77      3714\n",
      "weighted avg       0.80      0.76      0.77      3714\n",
      " samples avg       0.07      0.07      0.07      3714\n",
      "\n",
      "================================================================================\n",
      "Entity level evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total acc</th>\n",
       "      <th>total recall</th>\n",
       "      <th>total F1</th>\n",
       "      <th>PER F1</th>\n",
       "      <th>ORG F1</th>\n",
       "      <th>LOC F1</th>\n",
       "      <th>MISC F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default_BIO</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIO</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_IO</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total acc  total recall  total F1  PER F1  ORG F1  LOC F1  \\\n",
       "Default_BIO      0.672         0.627     0.649   0.586   0.794   0.687   \n",
       "Custom_BIO       0.778         0.750     0.764   0.714   0.806   0.774   \n",
       "Custom_IO        0.770         0.739     0.755   0.703   0.797   0.782   \n",
       "\n",
       "             MISC F1  \n",
       "Default_BIO    0.610  \n",
       "Custom_BIO     0.784  \n",
       "Custom_IO      0.765  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ned_IO = model.tag_sents(X_val_IO)\n",
    "y_pred_IO = [[word[1] for word in sent] for sent in pred_ned_IO]\n",
    "\n",
    "print(bio_classification_report(y_val_IO, y_pred_IO))\n",
    "print('='*80)\n",
    "print('Entity level evaluation')\n",
    "print('='*80)\n",
    "results, results_agg_ent = compute_metrics(ned_val_IO, pred_ned_IO)\n",
    "results_df = save_ent_results(\"Custom_IO\", results, results_agg_ent, results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**BIOS**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_train_BIOS = convert_BIO(ned_train, begin = True, single = True)\n",
    "ned_val_BIOS = convert_BIO(ned_val, begin = True, single = True)\n",
    "ned_test_BIOS = convert_BIO(ned_test, begin = True, single = True)\n",
    "\n",
    "X_val_BIOS = [[word[0] for word in sent] for sent in ned_val_BIOS]\n",
    "y_val_BIOS = [[word[1] for word in sent] for sent in ned_val_BIOS]\n",
    "X_test_BIOS = [[word[0] for word in sent] for sent in ned_test_BIOS]\n",
    "y_test_BIOS = [[word[1] for word in sent] for sent in ned_test_BIOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "customed_hyperparams = {'c1': 0.01, 'c2': 1, 'max_iterations': 100, 'feature.possible_transitions': False,\n",
    "                                            'feature.possible_states': True, 'feature.minfreq': 0}\n",
    "model = nltk.tag.CRFTagger(feature_func=Feature_getter(language='ned'), training_opt = customed_hyperparams)\n",
    "model.train(ned_train_BIOS, 'models/ned_customed_BIOS.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.58      0.30      0.39        61\n",
      "       I-LOC       0.57      0.33      0.42        64\n",
      "       S-LOC       0.78      0.84      0.81       418\n",
      "      B-MISC       0.72      0.57      0.64       212\n",
      "      I-MISC       0.62      0.54      0.58       215\n",
      "      S-MISC       0.80      0.77      0.78       536\n",
      "       B-ORG       0.85      0.70      0.77       298\n",
      "       I-ORG       0.86      0.65      0.74       396\n",
      "       S-ORG       0.81      0.54      0.64       388\n",
      "       B-PER       0.82      0.93      0.87       386\n",
      "       I-PER       0.81      0.95      0.87       423\n",
      "       S-PER       0.61      0.76      0.67       317\n",
      "\n",
      "   micro avg       0.77      0.73      0.75      3714\n",
      "   macro avg       0.74      0.66      0.68      3714\n",
      "weighted avg       0.77      0.73      0.74      3714\n",
      " samples avg       0.07      0.07      0.07      3714\n",
      "\n",
      "================================================================================\n",
      "Entity level evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total acc</th>\n",
       "      <th>total recall</th>\n",
       "      <th>total F1</th>\n",
       "      <th>PER F1</th>\n",
       "      <th>ORG F1</th>\n",
       "      <th>LOC F1</th>\n",
       "      <th>MISC F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default_BIO</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIO</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_IO</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIOS</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             total acc  total recall  total F1  PER F1  ORG F1  LOC F1  \\\n",
       "Default_BIO      0.672         0.627     0.649   0.586   0.794   0.687   \n",
       "Custom_BIO       0.778         0.750     0.764   0.714   0.806   0.774   \n",
       "Custom_IO        0.770         0.739     0.755   0.703   0.797   0.782   \n",
       "Custom_BIOS      0.763         0.735     0.749   0.711   0.789   0.760   \n",
       "\n",
       "             MISC F1  \n",
       "Default_BIO    0.610  \n",
       "Custom_BIO     0.784  \n",
       "Custom_IO      0.765  \n",
       "Custom_BIOS    0.757  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ned_BIOS = model.tag_sents(X_val_BIOS)\n",
    "y_pred_BIOS = [[word[1] for word in sent] for sent in pred_ned_BIOS]\n",
    "\n",
    "print(bio_classification_report(y_val_BIOS, y_pred_BIOS))\n",
    "print('='*80)\n",
    "print('Entity level evaluation')\n",
    "print('='*80)\n",
    "results, results_agg_ent = compute_metrics(ned_val_BIOS, pred_ned_BIOS)\n",
    "results_df = save_ent_results(\"Custom_BIOS\", results, results_agg_ent, results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family:Courier New; color:#994C00\">**BIOES**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_train_BIOES = convert_BIO(ned_train, begin = True, single = True, end = True)\n",
    "ned_val_BIOES = convert_BIO(ned_val, begin = True, single = True, end = True)\n",
    "ned_test_BIOES = convert_BIO(ned_test, begin = True, single = True, end = True)\n",
    "\n",
    "X_val_BIOES = [[word[0] for word in sent] for sent in ned_val_BIOES]\n",
    "y_val_BIOES = [[word[1] for word in sent] for sent in ned_val_BIOES]\n",
    "X_test_BIOES = [[word[0] for word in sent] for sent in ned_test_BIOES]\n",
    "y_test_BIOES = [[word[1] for word in sent] for sent in ned_test_BIOES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "customed_hyperparams = {'c1': 0.01, 'c2': 1, 'max_iterations': 100, 'feature.possible_transitions': False,\n",
    "                                            'feature.possible_states': True, 'feature.minfreq': 0}\n",
    "model = nltk.tag.CRFTagger(feature_func=Feature_getter(language='ned'), training_opt = customed_hyperparams)\n",
    "model.train(ned_train_BIOES, 'models/ned_customed_BIOES.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.63      0.28      0.39        61\n",
      "       E-LOC       0.65      0.30      0.41        50\n",
      "       I-LOC       0.50      0.14      0.22        14\n",
      "       S-LOC       0.77      0.84      0.80       418\n",
      "      B-MISC       0.68      0.59      0.63       212\n",
      "      E-MISC       0.56      0.57      0.56       127\n",
      "      I-MISC       0.61      0.43      0.51        88\n",
      "      S-MISC       0.79      0.78      0.79       536\n",
      "       B-ORG       0.86      0.69      0.77       298\n",
      "       E-ORG       0.86      0.70      0.77       276\n",
      "       I-ORG       0.84      0.38      0.53       120\n",
      "       S-ORG       0.81      0.54      0.65       388\n",
      "       B-PER       0.82      0.94      0.88       386\n",
      "       E-PER       0.82      0.95      0.88       380\n",
      "       I-PER       0.78      0.88      0.83        43\n",
      "       S-PER       0.60      0.75      0.67       317\n",
      "\n",
      "   micro avg       0.77      0.73      0.75      3714\n",
      "   macro avg       0.72      0.61      0.64      3714\n",
      "weighted avg       0.77      0.73      0.74      3714\n",
      " samples avg       0.07      0.07      0.07      3714\n",
      "\n",
      "================================================================================\n",
      "Entity level evaluation\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total acc</th>\n",
       "      <th>total recall</th>\n",
       "      <th>total F1</th>\n",
       "      <th>PER F1</th>\n",
       "      <th>ORG F1</th>\n",
       "      <th>LOC F1</th>\n",
       "      <th>MISC F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Default_BIO</th>\n",
       "      <td>0.672</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIO</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_IO</th>\n",
       "      <td>0.770</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIOS</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Custom_BIOES</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              total acc  total recall  total F1  PER F1  ORG F1  LOC F1  \\\n",
       "Default_BIO       0.672         0.627     0.649   0.586   0.794   0.687   \n",
       "Custom_BIO        0.778         0.750     0.764   0.714   0.806   0.774   \n",
       "Custom_IO         0.770         0.739     0.755   0.703   0.797   0.782   \n",
       "Custom_BIOS       0.763         0.735     0.749   0.711   0.789   0.760   \n",
       "Custom_BIOES      0.761         0.738     0.749   0.715   0.793   0.759   \n",
       "\n",
       "              MISC F1  \n",
       "Default_BIO     0.610  \n",
       "Custom_BIO      0.784  \n",
       "Custom_IO       0.765  \n",
       "Custom_BIOS     0.757  \n",
       "Custom_BIOES    0.752  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ned_BIOES = model.tag_sents(X_val_BIOES)\n",
    "y_pred_BIOES = [[word[1] for word in sent] for sent in pred_ned_BIOES]\n",
    "\n",
    "print(bio_classification_report(y_val_BIOES, y_pred_BIOES))\n",
    "print('='*80)\n",
    "print('Entity level evaluation')\n",
    "print('='*80)\n",
    "results, results_agg_ent = compute_metrics(ned_val_BIOES, pred_ned_BIOES)\n",
    "results_df = save_ent_results(\"Custom_BIOES\", results, results_agg_ent, results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:Courier New\">As we can see, the codification that works best is BIO, with the higher F1-score. If we look deeply at the results, as more predictable classes are added (i.e. BIOS and BIOES), the more the model struggles to perform well in all of them. Thus, betweem BIO and IO, despite results are similar, the capability of predicting entities is higher with BIO. Because of that we will continue improving with Custom_BIO model.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"font-family:Courier New; color:#336633\">**Adding Gazetteers**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''names =  []\n",
    "for sent in ned_train_BIO:\n",
    "    for token, label in sent:\n",
    "        if label == 'B-PER':\n",
    "            names.append(token)\n",
    "r = Counter(names)\n",
    "print(r.keys())'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
